此 project 是以 苏剑林 前輩的以下文章作為基礎, 我再用 ChatGPT, 修改. 目標是在任何文件中找到經常出現的詞語, 再把出現的次數輸出到Excel. 以下是引用文章資料:


苏剑林. (Oct. 26, 2015). 《新词发现的信息熵方法与实现 》[Blog post]. Retrieved from https://spaces.ac.cn/archives/3491
@online{kexuefm-3491,
        title={新词发现的信息熵方法与实现},
        author={苏剑林},
        year={2015},
        month={Oct},
        url={\url{https://spaces.ac.cn/archives/3491}},
} 


軟件的基本邏輯是利用 “信息熵” , 找出經常出現和有意義的字段.詳細邏輯請參閱蘇前輩的以上文章.

min_count
這是一個單詞在文本中必須出現的最小次數才能被考慮。出現次數少於min_count的單詞將被忽略。

min_support
在文本分析和關聯規則挖掘的上下文中，“支持度”是一個術語，指的是數據集中項集（一組項目，在這種情況下是單詞）的頻率或普遍性。
單詞的支持度是計算包含此單詞的交易（在這種情況下，句子或文檔）的比例。例如，如果我們有100個句子，單詞“蘋果”出現在其中的30個句子中，那麼“蘋果”的支持度就是30/100 = 0.3或30%。
min_support參數是一個閾值，用於過濾出支持度值小於此閾值的單詞。它用於忽略文本中不太頻繁的單詞。
因此，如果min_support設置為30，就意味著我們只考慮至少出現在所有句子或文檔的30%中的單詞。出現頻率較低的單詞在分析中不被考慮。
這個參數在關聯規則挖掘中非常重要，因為從不頻繁的單詞中得出的規則可能會誤導或無趣。通過設置適當的min_support值，我們可以關注文本中最相關的單詞。

min_s
這是一個單詞的最小熵。熵是衡量不確定性或隨機性的一種度量。熵越高，單詞在文本中獨立出現的可能性就越大。”
在信息理論中，熵是一種衡量信息的不確定性或隨機性的度量。在這裡，它被用來衡量一個單詞的出現是否是隨機的，或者說，這個單詞是否可能獨立於其他單詞出現。
例如，如果一個單詞在文本中的出現完全是隨機的，那麼我們可以說這個單詞的熵很高。相反，如果一個單詞總是在特定的上下文中出現，那麼我們可以說這個單詞的熵較低，因為它的出現並不是隨機的，而是由其上下文決定的。
min_s參數是一個閾值，用於過濾出熵值小於此閾值的單詞。這意味著，只有當一個單詞的熵大於或等於min_s時，我們才會考慮這個單詞。這可以幫助我們專注於那些可能獨立於其他單詞出現的單詞，從而忽略那些總是在特定上下文中出現的單詞。

